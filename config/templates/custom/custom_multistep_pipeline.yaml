# override 建议：
# - backends[1].config.base_url（CLI --override backends.1.config.base_url=http://localhost:8000/v1）
# - tasks[0].concurrency（CLI --override tasks.0.concurrency=4）
# - role_adapters[2].sandbox.max_output_tokens
api_version: gage/v1alpha1
kind: PipelineConfig
metadata:
  name: custom_multistep_pipeline
  description: 展示 support/inference/judge 手工编排
custom:
  steps:
    - step: support
      adapter_id: retriever_agent
    - step: inference
      adapter_id: dut_agent
    - step: judge
      adapter_id: judge_agent
    - step: auto_eval
datasets:
  - dataset_id: docqa_dev
    loader: hf_hub
    params:
      repo_id: my-org/docqa_dev
backends:
  - backend_id: retriever_backend
    type: faiss
    config:
      index_path: /mnt/vector/faiss.index
  - backend_id: dut_backend
    type: http
    config:
      base_url: http://localhost:8080/v1
prompts:
  - prompt_id: judge_template
    renderer: jinja
    template: |
      Context:
      {{ context }}

      Question:
      {{ question }}

      Model answer:
      {{ answer }}

      请输出 yes/no。
role_adapters:
  - adapter_id: retriever_agent
    role_type: support
    backend_id: retriever_backend
    capabilities:
      - retrieval
    resource_requirement:
      memory_gb: 16
  - adapter_id: dut_agent
    role_type: inference
    backend_id: dut_backend
    sandbox:
      max_output_tokens: 2048
  - adapter_id: judge_agent
    role_type: judge
    backend_id: dut_backend
    prompt_id: judge_template
metrics:
  - metric_id: rouge_l
    implementation: gage_eval.evaluation.metrics.builtin:ExactMatchMetric
    aggregation: mean
tasks:
  - task_id: docqa_dev_task
    dataset_id: docqa_dev
    steps:
      - step: support
        adapter_id: retriever_agent
      - step: inference
        adapter_id: dut_agent
      - step: judge
        adapter_id: judge_agent
      - step: auto_eval
    max_samples: 200
    shuffle: true
    concurrency: 8
    reporting:
      sinks:
        - type: file
          params:
            path: outputs/docqa_report.jsonl
