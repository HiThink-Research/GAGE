api_version: gage/v1alpha1
kind: PipelineConfig
metadata:
  name: mme_vllm_async
  description: 使用 vllm_backend 运行 MME (Multimodal Evaluation) 测试集评测。

custom:
  steps:
    - step: inference
    - step: auto_eval

# prompts:
#   - prompt_id: mme_infer_prompt
#     renderer: jinja
#     params:
#       system_prompt: |
#         你是一位擅长视觉理解的 AI 助手。请仔细查看图片并回答问题。
#         如果问题要求回答 yes 或 no，请只输出 Yes 或 No，不要添加其他内容。
#     template: |
#       {{ system_prompt }}
#
#       {{ sample.question }}

datasets:
  - dataset_id: mme_test
    hub: huggingface
    hub_params:
      hub_id: lmms-lab/MME
      split: test
    loader: hf_hub
    params:
      streaming: true
      bundle: mme
      preprocess: mme
      preprocess_kwargs:
        pre_encode_images: true

backends:
  - backend_id: mme_vllm_backend
    type: vllm
    config:
      # 需使用具备视觉能力的权重；默认指向本机已存在的模型目录
      model_path: /mnt/model/qwen2_5_vl_3b
      tokenizer_path: /mnt/model/qwen2_5_vl_3b
      force_tokenize_prompt: true
      tensor_parallel_size: 1
      max_tokens: 128
      sampling_params:
        temperature: 0.0
      max_batch_size: 1
      max_model_len: 8192
      gpu_memory_utilization: 0.9
      async_max_concurrency: 8
      output_type: text

role_adapters:
  - adapter_id: dut_mme_vllm_qwen
    role_type: dut_model
    backend_id: mme_vllm_backend
    # prompt_id: mme_infer_prompt
    capabilities:
      - chat_completion
      - multimodal_chat_completion

metrics:
  - metric_id: mme_acc
    implementation: mme_accuracy
    aggregation: mme_acc_plus  # Use MME-specific aggregator to compute acc and acc_plus

tasks:
  - task_id: mme_test_eval
    dataset_id: mme_test
    max_samples: 6
    reporting:
      sinks:
        - type: console
        - type: file
          params:
            output_path: ${GAGE_EVAL_SAVE_DIR:-./runs}/mme_vllm_events.jsonl
