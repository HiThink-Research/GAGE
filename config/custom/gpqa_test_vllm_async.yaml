api_version: gage/v1alpha1
kind: PipelineConfig
metadata:
  name: gpqa_legacy_vllm_async
  description: 使用 vllm_backend 运行 GPQA（extended）评测，沿用结构化 Prompt。

custom:
  steps:
    - step: inference
    - step: auto_eval



datasets:
  - dataset_id: gpqa_extended_local
    hub: huggingface
    hub_params:
      hub_id: Idavidrein/gpqa
      data_files:
        - repo_id: Idavidrein/gpqa
          path: gpqa_extended.csv
      builder_name: csv
      split: train
    loader: hf_hub
    params:
      preprocess: gpqa_multi_choice
      tokenizer_path: /mnt/model/qwen2_5_05B
backends:
  - backend_id: gpqa_legacy_vllm_backend
    type: vllm
    config:
      model_path: /mnt/model/qwen2_5_05B
      # tokenizer_path: ${GPQA_TOKENIZER_PATH:-/mnt/model/qwen2_5_05B}
      tensor_parallel_size: 1
      max_tokens: 128
      sampling_params:
        temperature: 0.0
        top_p: 0.8
      max_batch_size: 16
      max_model_len: 4096
      gpu_memory_utilization: 0.9
      async_max_concurrency: 32

role_adapters:
  - adapter_id: dut_gpqa_legacy_qwen
    role_type: dut_model
    backend_id: gpqa_legacy_vllm_backend
    capabilities:
      - chat_completion

metrics:
  - metric_id: gpqa_acc
    implementation: multi_choice_accuracy

tasks:
  - task_id: gpqa_extended_eval
    dataset_id: gpqa_extended_local
    max_samples: 546
    reporting:
      sinks:
        - type: console
        - type: file
          params:
            output_path: ${GAGE_EVAL_SAVE_DIR:-./runs}/gpqa_legacy_vllm_events.jsonl
