# =================================================================
# 只读模板快照（修改本段不影响模板定义）
# Template: local_single_judge_suite version=V1 monolithic=False
# -----------------------------------------------------------------
# Datasets:
#   - dataset_id: piqa_validation
#     loader: hf_hub
#     hub_params:
#       hub_id: piqa
#       split: validation
#     preprocess: piqa_struct_only
#     提示：可在 runtime.datasets.<id> 覆盖 hub_params.limit/local_path 等路径配置以指向本地测试集。
# Backends:
#   - backend_id: dut_local_openai_http
#     type: openai_http
#     model: qwen2.5-0.5b-instruct
#     base_url: http://127.0.0.1:1234/v1
#     async_max_concurrency: 4
#   - backend_id: judge_qwen3_openai_http
#     type: openai_http
#     model: qwen/qwen3-vl-30b
#     base_url: http://127.0.0.1:1234/v1
#     async_max_concurrency: 2
# Steps:
#   - step: inference
#     adapter_id: dut_qwen25_local
#   - step: judge
#     adapter_id: judge_qwen3
#   - step: auto_eval
#     adapter_id: <auto>
# Prompts（只读配置，修改请通过 PipelineConfig）：
#   提示：Prompts 属于评测逻辑的一部分，如需调整，请使用 run.py --init <name> --init-mode pipeline-config 生成 PipelineConfig 后在 prompts 段编辑。
#   - prompt_id: multi_choice_infer_prompt
#     renderer: jinja
#     used_by_adapters: dut_qwen25_local
#     params:
#       system_prompt: |
#         你是一个严谨的多选题助手，请逐步分析后在最后一行给出选项字母。
#       instruction: |
#         先简要说明理由，最后一行只输出一个大写字母（A、B、C 或 D），不需要其他符号。
#     template: |
#       {{ system_prompt }}
#       
#       问题：
#       {{ sample.get("question") or sample.get("goal") or sample.get("prompt") }}
#       
#       选项：
#       {% for label, text in (sample.get("metadata", {}).get("option_map") or {}).items() %}
#       {{ label }}. {{ text }}
#       {% endfor %}
#       
#       {{ instruction }}
#   - prompt_id: judge_multi_choice_prompt
#     renderer: jinja
#     used_by_adapters: judge_qwen3
#     params:
#       rubric: |
#         1）先复核题干与选项；2）判断被测模型的答案是否合理；3）必要时给出修正后的标准选项；4）给出 0-1 之间的分数与一句理由。
#     template: |
#       你是可靠的评测裁判，请基于题干、选项和被测模型回答进行判分。
#       {{ rubric }}
#       
#       题目：
#       {{ sample.get("question") or sample.get("goal") or sample.get("prompt") }}
#       
#       选项：
#       {% for label, text in (sample.get("metadata", {}).get("option_map") or {}).items() %}
#       {{ label }}. {{ text }}
#       {% endfor %}
#       
#       被测模型回答：
#       {% set output = payload.get("model_output") %}
#       {% if output is mapping %}
#       {{ output.get("answer") }}
#       {% elif output is sequence and output is not string %}
#       {% set first_item = output|first %}
#       {% if first_item is mapping %}
#       {{ first_item.get("answer") }}
#       {% else %}
#       {{ first_item }}
#       {% endif %}
#       {% else %}
#       {{ output }}
#       {% endif %}
#       
#       输出格式固定两行：
#       1) CORRECT: <最终确认的大写选项字母，例如 A>
#       2) SCORE: <0 到 1 的小数> 理由
# Metrics:
#   - metric_id: model_multi_choice_acc
#     implementation: multi_choice_accuracy
#   - metric_id: judge_multi_choice_acc
#     implementation: multi_choice_accuracy
#   - metric_id: latency
#     implementation: latency
# =================================================================
api_version: gage/v1alpha1

kind: RunConfig

metadata:
  name: local_single_judge_suite_run

base_task: builtin/local_single_judge_suite

template_version: V1

template_digest: sha256:04e4584be2090f91cb9ab6d76ef8d17ba1ad570c7cdd6c6e25c4ef3531276c43

# runtime 覆盖示例（按需修改下方键值）：
#   runtime.datasets.piqa_validation: {...}  # 可整体替换为本地数据集配置
#   runtime.backends.dut_local_openai_http: {...}  # 切换模型服务/参数
#   runtime.tasks.piqa_validation_with_judge.max_samples: 50  # 控制本次运行样本数
runtime:
  datasets:
    piqa_validation:
      hub: huggingface
      hub_params:
        hub_id: piqa
        split: validation
        trust_remote_code: true
      loader: hf_hub
      params:
        preprocess: piqa_struct_only
        streaming: false
  backends:
    dut_local_openai_http:
      type: openai_http
      config:
        base_url: http://127.0.0.1:1234/v1
        model: qwen2.5-0.5b-instruct
        default_params:
          max_new_tokens: 256
          temperature: 0.2
        async_max_concurrency: 4
    judge_qwen3_openai_http:
      type: openai_http
      config:
        base_url: http://127.0.0.1:1234/v1
        model: qwen/qwen3-vl-30b
        default_params:
          max_new_tokens: 256
          temperature: 0.3
        async_max_concurrency: 2
  tasks:
    piqa_validation_with_judge:
      max_samples: 5
      concurrency: 8
  global:
    output_path: ${GAGE_EVAL_SAVE_DIR:-./runs}/piqa_with_judge_events.jsonl