models:
  - name: qwen25_7b
    provider: together
    model_name: Qwen/Qwen2.5-7B-Instruct
    tokenizer_name: Qwen/Qwen2.5-7B-Instruct
    max_new_tokens: 16
    timeout: 120
    parallel_calls: 2
  - name: smollm3_3b
    provider: hf-inference
    model_name: HuggingFaceTB/SmolLM3-3B
    tokenizer_name: HuggingFaceTB/SmolLM3-3B
    max_new_tokens: 8
    timeout: 120
    parallel_calls: 1
  - name: kimi_k2_thinking
    provider: together
    model_name: moonshotai/Kimi-K2-Thinking
    tokenizer_name: moonshotai/Kimi-K2-Thinking
    max_new_tokens: 8
    timeout: 120
    parallel_calls: 1
  - name: llama31_8b_cerebras
    provider: cerebras
    model_name: meta-llama/Llama-3.1-8B-Instruct
    tokenizer_name: meta-llama/Llama-3.1-8B-Instruct
    max_new_tokens: 8
    timeout: 120
    parallel_calls: 1
  - name: llama3_8b_groq
    provider: groq
    model_name: meta-llama/Meta-Llama-3-8B-Instruct
    tokenizer_name: meta-llama/Meta-Llama-3-8B-Instruct
    max_new_tokens: 8
    timeout: 120
    parallel_calls: 1
  - name: aya_exp_32b_cohere
    provider: cohere
    model_name: CohereForAI/aya-expanse-32b
    tokenizer_name: CohereForAI/aya-expanse-32b
    max_new_tokens: 8
    timeout: 120
    parallel_calls: 1
  - name: apertus_8b_publicai
    provider: publicai
    model_name: swiss-ai/Apertus-8B-Instruct-2509
    tokenizer_name: swiss-ai/Apertus-8B-Instruct-2509
    max_new_tokens: 8
    timeout: 120
    parallel_calls: 1
  - name: glm46_zai_org
    provider: zai-org
    model_name: zai-org/GLM-4.6
    tokenizer_name: zai-org/GLM-4.6
    max_new_tokens: 8
    timeout: 120
    parallel_calls: 1

# 按需追加更多非 llama 模型：
# - name: your_model_id
#   provider: together
#   model_name: your/model
#   tokenizer_name: your/model
#   max_new_tokens: 16
#   timeout: 120
#   parallel_calls: 2
