api_version: gage/v1alpha1
kind: PipelineConfig
metadata:
  name: __PIPELINE_NAME__
  description: "litellm 后端最小闭环 demo（单模型，单任务，低成本参数）"

prompts:
  - prompt_id: piqa_infer_prompt
    renderer: jinja
    params:
      system_prompt: >
        你是一位擅长常识推理的助手，请阅读题目并在最后只输出正确选项对应的大写字母（A 或 B）。
      instruction: >
        请判断哪个答案更合理，并在最后一行仅输出一个大写字母（A 或 B）。
    template: |
      {{ system_prompt }}

      题目：
      {{ sample.goal }}

      选项：
      {% for label, text in (sample.metadata.option_map or {}).items() %}
      {{ label }}. {{ text }}
      {% endfor %}

      {{ instruction }}

datasets:
  - dataset_id: piqa_validation
    hub: huggingface
    hub_params:
      hub_id: piqa
      split: validation
      trust_remote_code: true
    loader: hf_hub
    params:
      preprocess: piqa_struct_only
      streaming: false

backends:
  - backend_id: __BACKEND_ID__
    type: litellm
    config:
      provider: "__PROVIDER__"
      # 为非官方模型名（如本地 OpenAI 兼容服务）显式传递 provider，避免 litellm 因 model 名无法推断 provider
      custom_llm_provider: "__PROVIDER__"
      model: "__MODEL_NAME__"
      api_base: "__API_BASE__"
      api_key: "__API_KEY__"
      timeout: __TIMEOUT__
      max_retries: 2
      retry_sleep: 1.0
      retry_multiplier: 2.0
      generation_parameters:
        max_new_tokens: __MAX_NEW_TOKENS__
        temperature: 0.0

role_adapters:
  - adapter_id: __ADAPTER_ID__
    role_type: dut_model
    backend_id: __BACKEND_ID__
    prompt_id: piqa_infer_prompt
    capabilities:
      - chat_completion

metrics:
  - metric_id: piqa_acc
    implementation: multi_choice_accuracy

tasks:
  - task_id: __TASK_ID__
    dataset_id: piqa_validation
    steps:
      - step: inference
        adapter_id: __ADAPTER_ID__
      - step: auto_eval
    max_samples: __MAX_SAMPLES__
    concurrency: __CONCURRENCY__
    reporting:
      sinks:
        - type: console
