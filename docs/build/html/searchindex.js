Search.setIndex({"alltitles": {"Contents:": [[0, null], [1, null], [6, null], [8, null], [12, null]], "Indices and tables": [[0, "indices-and-tables"]], "Installation": [[0, "installation"]], "Modules": [[0, "modules"]], "Quick Start": [[0, "quick-start"]], "inference": [[1, null]], "inference.data_server": [[2, null]], "inference.predict_async": [[3, null]], "inference.predict_multi_gpu": [[4, null]], "inference.preprocess": [[5, null]], "llm-eval documentation": [[0, null]], "main": [[6, null]], "run": [[7, null]], "tools": [[8, null]], "tools.ExternalApi": [[9, null]], "tools.HttpRequest": [[10, null]], "tools.PaasSubmitter": [[11, null]], "utils": [[12, null]], "utils.eval_MathVista_MINI": [[13, null]], "utils.eval_TextVQA_VAL": [[14, null]], "utils.eval_asr": [[15, null]], "utils.eval_mmmu": [[16, null]], "utils.eval_next_word_probability": [[17, null]], "utils.eval_ocr_bench": [[18, null]]}, "docnames": ["index", "inference", "inference/inference.data_server", "inference/inference.predict_async", "inference/inference.predict_multi_gpu", "inference/inference.preprocess", "main", "main/run", "tools", "tools/tools.ExternalApi", "tools/tools.HttpRequest", "tools/tools.PaasSubmitter", "utils", "utils/utils.eval_MathVista_MINI", "utils/utils.eval_TextVQA_VAL", "utils/utils.eval_asr", "utils/utils.eval_mmmu", "utils/utils.eval_next_word_probability", "utils/utils.eval_ocr_bench"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1}, "filenames": ["index.rst", "inference.rst", "inference/inference.data_server.rst", "inference/inference.predict_async.rst", "inference/inference.predict_multi_gpu.rst", "inference/inference.preprocess.rst", "main.rst", "main/run.rst", "tools.rst", "tools/tools.ExternalApi.rst", "tools/tools.HttpRequest.rst", "tools/tools.PaasSubmitter.rst", "utils.rst", "utils/utils.eval_MathVista_MINI.rst", "utils/utils.eval_TextVQA_VAL.rst", "utils/utils.eval_asr.rst", "utils/utils.eval_mmmu.rst", "utils/utils.eval_next_word_probability.rst", "utils/utils.eval_ocr_bench.rst"], "indexentries": {"__init__() \uff08inference.data_server.filedata \u65b9\u6cd5\uff09": [[2, "inference.data_server.FileData.__init__", false]], "__init__() \uff08inference.data_server.sample \u65b9\u6cd5\uff09": [[2, "inference.data_server.Sample.__init__", false]], "__init__() \uff08tools.externalapi.asyncllmclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.__init__", false]], "__init__() \uff08tools.externalapi.claudeclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.CLAUDEClient.__init__", false]], "__init__() \uff08tools.externalapi.deepseekclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.DEEPSEEKClient.__init__", false]], "__init__() \uff08tools.externalapi.geminiclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.GEMINIClient.__init__", false]], "__init__() \uff08tools.externalapi.gpt4oclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.GPT4OClient.__init__", false]], "__init__() \uff08tools.externalapi.kimiclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.KIMIClient.__init__", false]], "__init__() \uff08tools.externalapi.othergptclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.OtherGPTClient.__init__", false]], "__init__() \uff08tools.httprequest.httprequest \u65b9\u6cd5\uff09": [[10, "tools.HttpRequest.HTTPRequest.__init__", false]], "__init__() \uff08tools.paassubmitter.progressfile \u65b9\u6cd5\uff09": [[11, "tools.PaasSubmitter.ProgressFile.__init__", false]], "__init__() \uff08tools.paassubmitter.submiter \u65b9\u6cd5\uff09": [[11, "tools.PaasSubmitter.Submiter.__init__", false]], "add_dataset_for_prediction()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.add_dataset_for_prediction", false]], "add_file_for_prediction()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.add_file_for_prediction", false]], "add_json_file_for_prediction()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.add_json_file_for_prediction", false]], "asyncllmclient\uff08tools.externalapi \u4e2d\u7684\u7c7b\uff09": [[9, "tools.ExternalApi.AsyncLLMClient", false]], "build_mathvista_gpt4_prompt()\uff08\u5728 utils.eval_mathvista_mini \u6a21\u5757\u4e2d\uff09": [[13, "utils.eval_MathVista_MINI.build_mathvista_gpt4_prompt", false]], "build_prompt()\uff08\u5728 utils.eval_mmmu \u6a21\u5757\u4e2d\uff09": [[16, "utils.eval_mmmu.build_prompt", false]], "check_for_multi_modal()\uff08\u5728 inference.preprocess \u6a21\u5757\u4e2d\uff09": [[5, "inference.preprocess.check_for_multi_modal", false]], "check_inference_engine_running()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.check_inference_engine_running", false]], "claudeclient\uff08tools.externalapi \u4e2d\u7684\u7c7b\uff09": [[9, "tools.ExternalApi.CLAUDEClient", false]], "close() \uff08tools.externalapi.asyncllmclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.close", false]], "convert_output_ids_to_text()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.convert_output_ids_to_text", false]], "convert_sample_to_input_ids()\uff08\u5728 inference.preprocess \u6a21\u5757\u4e2d\uff09": [[5, "inference.preprocess.convert_sample_to_input_ids", false]], "data_preprocess()\uff08\u5728 utils.eval_mathvista_mini \u6a21\u5757\u4e2d\uff09": [[13, "utils.eval_MathVista_MINI.data_preprocess", false]], "data_preprocess()\uff08\u5728 utils.eval_mmmu \u6a21\u5757\u4e2d\uff09": [[16, "utils.eval_mmmu.data_preprocess", false]], "debug()\uff08\u5728 tools.externalapi \u6a21\u5757\u4e2d\uff09": [[9, "tools.ExternalApi.debug", false]], "deepseekclient\uff08tools.externalapi \u4e2d\u7684\u7c7b\uff09": [[9, "tools.ExternalApi.DEEPSEEKClient", false]], "done_event\uff08inference.data_server.sample \u5c5e\u6027\uff09": [[2, "inference.data_server.Sample.done_event", false]], "evaluation()\uff08\u5728 utils.eval_mathvista_mini \u6a21\u5757\u4e2d\uff09": [[13, "utils.eval_MathVista_MINI.evaluation", false]], "evaluation()\uff08\u5728 utils.eval_mmmu \u6a21\u5757\u4e2d\uff09": [[16, "utils.eval_mmmu.evaluation", false]], "evaluation()\uff08\u5728 utils.eval_next_word_probability \u6a21\u5757\u4e2d\uff09": [[17, "utils.eval_next_word_probability.evaluation", false]], "evaluation()\uff08\u5728 utils.eval_ocr_bench \u6a21\u5757\u4e2d\uff09": [[18, "utils.eval_ocr_bench.evaluation", false]], "evaluation()\uff08\u5728 utils.eval_textvqa_val \u6a21\u5757\u4e2d\uff09": [[14, "utils.eval_TextVQA_VAL.evaluation", false]], "extract_answer_info()\uff08\u5728 utils.eval_mathvista_mini \u6a21\u5757\u4e2d\uff09": [[13, "utils.eval_MathVista_MINI.extract_answer_info", false]], "file_type\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.file_type", false]], "filedata\uff08inference.data_server \u4e2d\u7684\u7c7b\uff09": [[2, "inference.data_server.FileData", false]], "find_key_in_nested_dict()\uff08tools.externalapi.asyncllmclient \u9759\u6001\u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.find_key_in_nested_dict", false]], "geminiclient\uff08tools.externalapi \u4e2d\u7684\u7c7b\uff09": [[9, "tools.ExternalApi.GEMINIClient", false]], "generation_params\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.generation_params", false]], "get() \uff08tools.httprequest.httprequest \u65b9\u6cd5\uff09": [[10, "tools.HttpRequest.HTTPRequest.get", false]], "get_data()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.get_data", false]], "get_file()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.get_file", false]], "get_file_info()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.get_file_info", false]], "get_gpt4_ice()\uff08\u5728 utils.eval_mathvista_mini \u6a21\u5757\u4e2d\uff09": [[13, "utils.eval_MathVista_MINI.get_gpt4_ICE", false]], "get_gpt_response() \uff08tools.externalapi.asyncllmclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.get_gpt_response", false]], "get_info()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.get_info", false]], "get_num_done()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.get_num_done", false]], "get_preprocess_func()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.get_preprocess_func", false]], "get_prompt()\uff08\u5728 inference.preprocess \u6a21\u5757\u4e2d\uff09": [[5, "inference.preprocess.get_prompt", false]], "gpt4oclient\uff08tools.externalapi \u4e2d\u7684\u7c7b\uff09": [[9, "tools.ExternalApi.GPT4OClient", false]], "hit_calculate()\uff08\u5728 utils.eval_textvqa_val \u6a21\u5757\u4e2d\uff09": [[14, "utils.eval_TextVQA_VAL.hit_calculate", false]], "httprequest\uff08tools.httprequest \u4e2d\u7684\u7c7b\uff09": [[10, "tools.HttpRequest.HTTPRequest", false]], "image2text() \uff08tools.externalapi.asyncllmclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.image2text", false]], "images2texts() \uff08tools.externalapi.asyncllmclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.images2texts", false]], "inference.data_server": [[2, "module-inference.data_server", false]], "inference.predict_multi_gpu": [[4, "module-inference.predict_multi_gpu", false]], "inference.preprocess": [[5, "module-inference.preprocess", false]], "initialize() \uff08tools.externalapi.asyncllmclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.initialize", false]], "input_path\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.input_path", false]], "inputs\uff08inference.data_server.sample \u5c5e\u6027\uff09": [[2, "inference.data_server.Sample.inputs", false]], "is_done\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.is_done", false]], "is_file_all_done()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.is_file_all_done", false]], "is_file_all_read()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.is_file_all_read", false]], "is_gpu_idle()\uff08\u5728 inference.predict_multi_gpu \u6a21\u5757\u4e2d\uff09": [[4, "inference.predict_multi_gpu.is_gpu_idle", false]], "istype()\uff08\u5728 utils.eval_textvqa_val \u6a21\u5757\u4e2d\uff09": [[14, "utils.eval_TextVQA_VAL.istype", false]], "j_pred\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.j_pred", false]], "kimiclient\uff08tools.externalapi \u4e2d\u7684\u7c7b\uff09": [[9, "tools.ExternalApi.KIMIClient", false]], "llm_eval()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.llm_eval", false]], "load_dataset()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.load_dataset", false]], "load_file()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.load_file", false]], "load_json_file()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.load_json_file", false]], "load_tokenizer()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.load_tokenizer", false]], "main()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.main", false]], "maybe_start_judge_model()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.maybe_start_judge_model", false]], "module": [[2, "module-inference.data_server", false], [4, "module-inference.predict_multi_gpu", false], [5, "module-inference.preprocess", false], [7, "module-run", false], [9, "module-tools.ExternalApi", false], [10, "module-tools.HttpRequest", false], [11, "module-tools.PaasSubmitter", false], [13, "module-utils.eval_MathVista_MINI", false], [14, "module-utils.eval_TextVQA_VAL", false], [16, "module-utils.eval_mmmu", false], [17, "module-utils.eval_next_word_probability", false], [18, "module-utils.eval_ocr_bench", false]], "n_pred\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.n_pred", false]], "n_write\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.n_write", false]], "next_token_ids\uff08inference.data_server.sample \u5c5e\u6027\uff09": [[2, "inference.data_server.Sample.next_token_ids", false]], "othergptclient\uff08tools.externalapi \u4e2d\u7684\u7c7b\uff09": [[9, "tools.ExternalApi.OtherGPTClient", false]], "output_key\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.output_key", false]], "output_path\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.output_path", false]], "output_type\uff08inference.data_server.sample \u5c5e\u6027\uff09": [[2, "inference.data_server.Sample.output_type", false]], "output\uff08inference.data_server.sample \u5c5e\u6027\uff09": [[2, "inference.data_server.Sample.output", false]], "post() \uff08tools.httprequest.httprequest \u65b9\u6cd5\uff09": [[10, "tools.HttpRequest.HTTPRequest.post", false]], "post_file()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.post_file", false]], "post_inputs()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.post_inputs", false]], "post_result()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.post_result", false]], "post_start()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.post_start", false]], "post_terminate()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.post_terminate", false]], "preprocess\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.preprocess", false]], "print_subprocess_out_err()\uff08\u5728 inference.predict_multi_gpu \u6a21\u5757\u4e2d\uff09": [[4, "inference.predict_multi_gpu.print_subprocess_out_err", false]], "process_answer()\uff08\u5728 utils.eval_textvqa_val \u6a21\u5757\u4e2d\uff09": [[14, "utils.eval_TextVQA_VAL.process_answer", false]], "process_line()\uff08\u5728 utils.eval_textvqa_val \u6a21\u5757\u4e2d\uff09": [[14, "utils.eval_TextVQA_VAL.process_line", false]], "process_messages()\uff08\u5728 inference.preprocess \u6a21\u5757\u4e2d\uff09": [[5, "inference.preprocess.process_messages", false]], "process_punctuation()\uff08\u5728 utils.eval_textvqa_val \u6a21\u5757\u4e2d\uff09": [[14, "utils.eval_TextVQA_VAL.process_punctuation", false]], "progressfile\uff08tools.paassubmitter \u4e2d\u7684\u7c7b\uff09": [[11, "tools.PaasSubmitter.ProgressFile", false]], "read() \uff08tools.paassubmitter.progressfile \u65b9\u6cd5\uff09": [[11, "tools.PaasSubmitter.ProgressFile.read", false]], "read\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.read", false]], "refresh_authority() \uff08tools.externalapi.asyncllmclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.refresh_authority", false]], "remove_stop_str()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.remove_stop_str", false]], "results_new\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.results_new", false]], "results\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.results", false]], "run": [[7, "module-run", false]], "run_command()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.run_command", false]], "run_judge_inference()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.run_judge_inference", false]], "run_loss_eval()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.run_loss_eval", false]], "run_mt_bench_eval()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.run_mt_bench_eval", false]], "run_next_word_prob_eval()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.run_next_word_prob_eval", false]], "run_post_eval()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.run_post_eval", false]], "run_predict_multi_gpu()\uff08\u5728 inference.predict_multi_gpu \u6a21\u5757\u4e2d\uff09": [[4, "inference.predict_multi_gpu.run_predict_multi_gpu", false]], "run_task_inference()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.run_task_inference", false]], "run_text_eval()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.run_text_eval", false]], "samples\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.samples", false]], "sample\uff08inference.data_server \u4e2d\u7684\u7c7b\uff09": [[2, "inference.data_server.Sample", false]], "save_file()\uff08tools.externalapi.asyncllmclient \u9759\u6001\u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.save_file", false]], "send_request()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.send_request", false]], "set_header() \uff08tools.httprequest.httprequest \u65b9\u6cd5\uff09": [[10, "tools.HttpRequest.HTTPRequest.set_header", false]], "set_result()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.set_result", false]], "submit_result() \uff08tools.paassubmitter.submiter \u65b9\u6cd5\uff09": [[11, "tools.PaasSubmitter.Submiter.submit_result", false]], "submiter\uff08tools.paassubmitter \u4e2d\u7684\u7c7b\uff09": [[11, "tools.PaasSubmitter.Submiter", false]], "terminate_inference_engine()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.terminate_inference_engine", false]], "terminate_subprocess()\uff08\u5728 inference.predict_multi_gpu \u6a21\u5757\u4e2d\uff09": [[4, "inference.predict_multi_gpu.terminate_subprocess", false]], "text2text() \uff08tools.externalapi.asyncllmclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.text2text", false]], "text2text() \uff08tools.externalapi.othergptclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.OtherGPTClient.text2text", false]], "texts2texts() \uff08tools.externalapi.asyncllmclient \u65b9\u6cd5\uff09": [[9, "tools.ExternalApi.AsyncLLMClient.texts2texts", false]], "tools.externalapi": [[9, "module-tools.ExternalApi", false]], "tools.httprequest": [[10, "module-tools.HttpRequest", false]], "tools.paassubmitter": [[11, "module-tools.PaasSubmitter", false]], "uid\uff08inference.data_server.sample \u5c5e\u6027\uff09": [[2, "inference.data_server.Sample.uid", false]], "upload_pass_format()\uff08\u5728 utils.eval_mmmu \u6a21\u5757\u4e2d\uff09": [[16, "utils.eval_mmmu.upload_pass_format", false]], "utils.eval_mathvista_mini": [[13, "module-utils.eval_MathVista_MINI", false]], "utils.eval_mmmu": [[16, "module-utils.eval_mmmu", false]], "utils.eval_next_word_probability": [[17, "module-utils.eval_next_word_probability", false]], "utils.eval_ocr_bench": [[18, "module-utils.eval_ocr_bench", false]], "utils.eval_textvqa_val": [[14, "module-utils.eval_TextVQA_VAL", false]], "wait_for_external_api()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.wait_for_external_api", false]], "wait_for_inference()\uff08\u5728 run \u6a21\u5757\u4e2d\uff09": [[7, "run.wait_for_inference", false]], "write_result()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.write_result", false]], "write_result_async()\uff08\u5728 inference.data_server \u6a21\u5757\u4e2d\uff09": [[2, "inference.data_server.write_result_async", false]], "write\uff08inference.data_server.filedata \u5c5e\u6027\uff09": [[2, "inference.data_server.FileData.write", false]]}, "objects": {"": [[7, 0, 0, "-", "run"]], "inference": [[2, 0, 0, "-", "data_server"], [4, 0, 0, "-", "predict_multi_gpu"], [5, 0, 0, "-", "preprocess"]], "inference.data_server": [[2, 1, 1, "", "FileData"], [2, 1, 1, "", "Sample"], [2, 4, 1, "", "add_dataset_for_prediction"], [2, 4, 1, "", "add_file_for_prediction"], [2, 4, 1, "", "add_json_file_for_prediction"], [2, 4, 1, "", "convert_output_ids_to_text"], [2, 4, 1, "", "get_data"], [2, 4, 1, "", "get_file"], [2, 4, 1, "", "get_file_info"], [2, 4, 1, "", "get_info"], [2, 4, 1, "", "get_num_done"], [2, 4, 1, "", "get_preprocess_func"], [2, 4, 1, "", "is_file_all_done"], [2, 4, 1, "", "is_file_all_read"], [2, 4, 1, "", "load_dataset"], [2, 4, 1, "", "load_file"], [2, 4, 1, "", "load_json_file"], [2, 4, 1, "", "load_tokenizer"], [2, 4, 1, "", "post_file"], [2, 4, 1, "", "post_inputs"], [2, 4, 1, "", "post_result"], [2, 4, 1, "", "post_start"], [2, 4, 1, "", "post_terminate"], [2, 4, 1, "", "remove_stop_str"], [2, 4, 1, "", "set_result"], [2, 4, 1, "", "write_result"], [2, 4, 1, "", "write_result_async"]], "inference.data_server.FileData": [[2, 2, 1, "", "__init__"], [2, 3, 1, "", "file_type"], [2, 3, 1, "", "generation_params"], [2, 3, 1, "", "input_path"], [2, 3, 1, "", "is_done"], [2, 3, 1, "", "j_pred"], [2, 3, 1, "", "n_pred"], [2, 3, 1, "", "n_write"], [2, 3, 1, "", "output_key"], [2, 3, 1, "", "output_path"], [2, 3, 1, "", "preprocess"], [2, 3, 1, "", "read"], [2, 3, 1, "", "results"], [2, 3, 1, "", "results_new"], [2, 3, 1, "", "samples"], [2, 3, 1, "", "write"]], "inference.data_server.Sample": [[2, 2, 1, "", "__init__"], [2, 3, 1, "", "done_event"], [2, 3, 1, "", "inputs"], [2, 3, 1, "", "next_token_ids"], [2, 3, 1, "", "output"], [2, 3, 1, "", "output_type"], [2, 3, 1, "", "uid"]], "inference.predict_multi_gpu": [[4, 4, 1, "", "is_gpu_idle"], [4, 4, 1, "", "print_subprocess_out_err"], [4, 4, 1, "", "run_predict_multi_gpu"], [4, 4, 1, "", "terminate_subprocess"]], "inference.preprocess": [[5, 4, 1, "", "check_for_multi_modal"], [5, 4, 1, "", "convert_sample_to_input_ids"], [5, 4, 1, "", "get_prompt"], [5, 4, 1, "", "process_messages"]], "run": [[7, 4, 1, "", "check_inference_engine_running"], [7, 4, 1, "", "llm_eval"], [7, 4, 1, "", "main"], [7, 4, 1, "", "maybe_start_judge_model"], [7, 4, 1, "", "run_command"], [7, 4, 1, "", "run_judge_inference"], [7, 4, 1, "", "run_loss_eval"], [7, 4, 1, "", "run_mt_bench_eval"], [7, 4, 1, "", "run_next_word_prob_eval"], [7, 4, 1, "", "run_post_eval"], [7, 4, 1, "", "run_task_inference"], [7, 4, 1, "", "run_text_eval"], [7, 4, 1, "", "send_request"], [7, 4, 1, "", "terminate_inference_engine"], [7, 4, 1, "", "wait_for_external_api"], [7, 4, 1, "", "wait_for_inference"]], "tools": [[9, 0, 0, "-", "ExternalApi"], [10, 0, 0, "-", "HttpRequest"], [11, 0, 0, "-", "PaasSubmitter"]], "tools.ExternalApi": [[9, 1, 1, "", "AsyncLLMClient"], [9, 1, 1, "", "CLAUDEClient"], [9, 1, 1, "", "DEEPSEEKClient"], [9, 1, 1, "", "GEMINIClient"], [9, 1, 1, "", "GPT4OClient"], [9, 1, 1, "", "KIMIClient"], [9, 1, 1, "", "OtherGPTClient"], [9, 4, 1, "", "debug"]], "tools.ExternalApi.AsyncLLMClient": [[9, 2, 1, "", "__init__"], [9, 2, 1, "", "close"], [9, 2, 1, "", "find_key_in_nested_dict"], [9, 2, 1, "", "get_gpt_response"], [9, 2, 1, "", "image2text"], [9, 2, 1, "", "images2texts"], [9, 2, 1, "", "initialize"], [9, 2, 1, "", "refresh_authority"], [9, 2, 1, "", "save_file"], [9, 2, 1, "", "text2text"], [9, 2, 1, "", "texts2texts"]], "tools.ExternalApi.CLAUDEClient": [[9, 2, 1, "", "__init__"]], "tools.ExternalApi.DEEPSEEKClient": [[9, 2, 1, "", "__init__"]], "tools.ExternalApi.GEMINIClient": [[9, 2, 1, "", "__init__"]], "tools.ExternalApi.GPT4OClient": [[9, 2, 1, "", "__init__"]], "tools.ExternalApi.KIMIClient": [[9, 2, 1, "", "__init__"]], "tools.ExternalApi.OtherGPTClient": [[9, 2, 1, "", "__init__"], [9, 2, 1, "", "text2text"]], "tools.HttpRequest": [[10, 1, 1, "", "HTTPRequest"]], "tools.HttpRequest.HTTPRequest": [[10, 2, 1, "", "__init__"], [10, 2, 1, "", "get"], [10, 2, 1, "", "post"], [10, 2, 1, "", "set_header"]], "tools.PaasSubmitter": [[11, 1, 1, "", "ProgressFile"], [11, 1, 1, "", "Submiter"]], "tools.PaasSubmitter.ProgressFile": [[11, 2, 1, "", "__init__"], [11, 2, 1, "", "read"]], "tools.PaasSubmitter.Submiter": [[11, 2, 1, "", "__init__"], [11, 2, 1, "", "submit_result"]], "utils": [[13, 0, 0, "-", "eval_MathVista_MINI"], [14, 0, 0, "-", "eval_TextVQA_VAL"], [16, 0, 0, "-", "eval_mmmu"], [17, 0, 0, "-", "eval_next_word_probability"], [18, 0, 0, "-", "eval_ocr_bench"]], "utils.eval_MathVista_MINI": [[13, 4, 1, "", "build_mathvista_gpt4_prompt"], [13, 4, 1, "", "data_preprocess"], [13, 4, 1, "", "evaluation"], [13, 4, 1, "", "extract_answer_info"], [13, 4, 1, "", "get_gpt4_ICE"]], "utils.eval_TextVQA_VAL": [[14, 4, 1, "", "evaluation"], [14, 4, 1, "", "hit_calculate"], [14, 4, 1, "", "istype"], [14, 4, 1, "", "process_answer"], [14, 4, 1, "", "process_line"], [14, 4, 1, "", "process_punctuation"]], "utils.eval_mmmu": [[16, 4, 1, "", "build_prompt"], [16, 4, 1, "", "data_preprocess"], [16, 4, 1, "", "evaluation"], [16, 4, 1, "", "upload_pass_format"]], "utils.eval_next_word_probability": [[17, 4, 1, "", "evaluation"]], "utils.eval_ocr_bench": [[18, 4, 1, "", "evaluation"]]}, "objnames": {"0": ["py", "module", "Python \u6a21\u5757"], "1": ["py", "class", "Python \u7c7b"], "2": ["py", "method", "Python \u65b9\u6cd5"], "3": ["py", "attribute", "Python \u5c5e\u6027"], "4": ["py", "function", "Python \u51fd\u6570"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function"}, "terms": {"--": [2, 7, 9, 10, 16, 18], "...": 0, ".__": [1, 8], "0.0": 9, "0.85": [16, 18], "10": 7, "10jqka": 9, "2.0": 9, "20": 9, "200": 9, "20241022": 9, "20250204210426": 9, "30": 10, "4o": 9, "5cafd46a3b2342b5a903afafc38d4aef": 9, "60": [7, 9], "800": 9, "8443": 9, "85": [16, 18], "8k": 9, "__": [1, 2, 8, 9, 10, 11], "__init__": [1, 2, 8, 9, 10, 11], "access": 9, "add": [0, 1, 2], "add_dataset_for_predict": [0, 1, 2], "add_file_for_predict": [0, 1, 2], "add_json_file_for_predict": [0, 1, 2], "ai": 9, "ai_access": 9, "all": [0, 1, 2], "answer": [0, 12, 13, 14, 16], "anthrop": 9, "api": [0, 6, 7, 9, 10], "api_key": 9, "app": 9, "app_id": 9, "app_secret": 9, "arg": [4, 7], "arsenal": 9, "asr": [0, 12], "async": [0, 1, 2, 4, 7, 9], "asyncllmcli": [0, 8, 9], "audio": 5, "auth": 9, "author": [8, 9], "await": 7, "base": [9, 10], "base_url": [9, 10], "bench": [0, 6, 7, 12], "bool": 2, "build": [0, 12, 13, 16], "build_mathvista_gpt4_prompt": [0, 12, 13], "build_prompt": [0, 12, 16], "by": 13, "calcul": [0, 12, 14], "chat": 9, "chat_url": 9, "chatgpt": 9, "check": [0, 1, 5, 6, 7], "check_for_multi_mod": [0, 1, 5], "check_inference_engine_run": [0, 6, 7], "class": [2, 9, 10, 11], "claud": 9, "claudecli": [0, 8, 9], "close": [8, 9], "cmd": 7, "cn": 9, "com": 9, "command": [0, 6, 7], "complet": 9, "config": [7, 11], "context": 13, "convert": [0, 1, 2, 5], "convert_output_ids_to_text": [0, 1, 2], "convert_sample_to_input_id": [0, 1, 5], "data": [0, 1, 4, 7, 10, 11, 12, 13, 16, 18], "data_path": 2, "data_preprocess": [0, 12, 13, 16], "data_serv": [0, 1, 4], "data_typ": 2, "dataset": [0, 1, 2], "debug": [0, 8, 9], "deepseekcli": [0, 8, 9], "detail": [0, 11], "detailed_data_path": 11, "dict": [2, 7, 8, 9, 10, 16], "dir": [2, 7, 13, 16], "done": [0, 1, 2], "done_ev": [1, 2], "doubao": 9, "endpoint": 10, "engin": [0, 6, 7], "ep": 9, "err": [0, 1, 4], "eval": [6, 7, 12], "eval_asr": [0, 12], "eval_fil": 14, "eval_mathvista_mini": [0, 12], "eval_mmmu": [0, 12], "eval_next_word_prob": [0, 12], "eval_ocr_bench": [0, 12], "eval_textvqa_v": [0, 12], "evalu": [0, 12, 13, 14, 16, 17, 18], "event": [1, 2], "exampl": [13, 16], "extern": [0, 6, 7], "external_api": 7, "externalapi": [0, 7, 8], "extract": [0, 12, 13], "extract_answer_info": [0, 12, 13], "factori": 2, "fals": [2, 5], "file": [0, 1, 2, 7, 8, 9, 10, 13, 14, 16], "file_path": 7, "file_typ": [1, 2], "filedata": [0, 1, 2], "filenam": 11, "find": [8, 9], "find_key_in_nested_dict": [8, 9], "flash": 9, "float": [2, 9, 16, 18], "for": [0, 1, 2, 5, 6, 7, 13], "format": [0, 12, 16], "from": 13, "func": [0, 1, 2], "function": [2, 4, 5, 7, 9, 13, 14, 16, 17, 18], "gclbn": 9, "gemini": 9, "geminicli": [0, 8, 9], "generat": [1, 2], "generation_param": [1, 2], "get": [0, 1, 2, 5, 8, 9, 10, 12, 13], "get_data": [0, 1, 2], "get_fil": [0, 1, 2], "get_file_info": [0, 1, 2], "get_gpt4_ic": [0, 12, 13], "get_gpt_respons": [8, 9], "get_info": [0, 1, 2], "get_num_don": [0, 1, 2], "get_preprocess_func": [0, 1, 2], "get_prompt": [0, 1, 5], "gpt": [8, 9, 13], "gpt4": [0, 12, 13], "gpt4oclient": [0, 8, 9], "gpu": [0, 1, 2, 7], "header": [8, 10], "hit": [0, 12, 14], "hit_calcul": [0, 12, 14], "http": 10, "httprequest": [0, 8], "https": 9, "i_data": 2, "i_sampl": 2, "ice": [0, 12, 13], "id": [0, 1, 9], "idl": [0, 1, 4], "ids": [2, 5], "imag": [5, 7, 9], "image2text": [8, 9], "image_url": 7, "images2text": [7, 8, 9], "in": [8, 9, 13, 14], "in_text": 14, "infer": [0, 6, 7], "info": [0, 1, 2, 12, 13], "init": [1, 2, 8, 9, 10, 11], "initi": [8, 9], "input": [0, 1, 2, 5, 7, 9, 13, 16, 17, 18], "input_fil": [13, 16], "input_path": [1, 2, 7, 13, 16, 17, 18], "instruct": 9, "int": [2, 7, 9, 10], "interv": 7, "is": [0, 1, 2, 4, 5, 16], "is_don": [1, 2], "is_file_all_don": [0, 1, 2], "is_file_all_read": [0, 1, 2], "is_gpu_idl": [0, 1, 4], "is_multi_mod": 5, "is_return_dict": 16, "istyp": [0, 12, 14], "iv": 9, "j_pred": [1, 2], "jqka": 9, "json": [0, 1, 2, 7, 13, 16, 18], "jsonl": [2, 7], "judg": [0, 6, 7], "judge_model_port": 7, "jzxhtqkrpymxx1u9hnyxejjnzcuhlbckmt": 9, "key": [1, 2, 8, 9, 10], "kimi": 9, "kimi_moonshot": 9, "kimicli": [0, 8, 9], "kwarg": [16, 18], "line": [0, 12, 13, 14], "list": [2, 5, 7, 9], "llm": [6, 7], "llm_eval": [0, 6, 7], "load": [0, 1, 2], "load_dataset": [0, 1, 2], "load_fil": [0, 1, 2], "load_json_fil": [0, 1, 2], "load_token": [0, 1, 2], "login": 9, "loss": [0, 6, 7], "lsyie": 9, "main": [0, 7, 13, 14], "manual": 2, "manual_start": 2, "mathvista": [0, 12], "max": 7, "max_retri": 7, "mayb": [0, 6, 7], "maybe_start_judge_model": [0, 6, 7], "messag": [0, 1, 5, 9], "method": 7, "mini": [0, 12], "mmmu": [0, 12], "modal": [0, 1, 5], "model": [0, 6, 7, 9, 16], "model_nam": 7, "model_path": 7, "model_prompt_tmpl": 16, "modul": 7, "moonshot": 9, "mt": [0, 6, 7], "multi": [0, 1, 2, 5], "n_pred": [1, 2], "n_write": [1, 2], "name": 7, "nest": [8, 9], "nested_dict": 9, "new": [1, 2], "next": [0, 1, 2, 6, 7, 12], "next_token_id": [1, 2], "none": [2, 7, 9, 10, 16], "num": [0, 1, 2, 9], "oauth": 9, "obj": 9, "object": 7, "ocr": [0, 12], "openai": 9, "openai.10": 9, "option": [2, 10], "othergptcli": [0, 8, 9], "out": [0, 1, 4], "output": [0, 1, 2, 7, 9], "output_dir": 2, "output_fil": 9, "output_id": 2, "output_key": [1, 2], "output_path": [1, 2, 7], "output_typ": [1, 2], "paassubmitt": [0, 8], "param": [1, 2, 10], "pars": 13, "pass": [0, 12, 16], "path": [1, 2, 5, 7, 9, 11, 13, 16, 17, 18], "pbar": 9, "pip": 0, "port": 7, "post": [0, 1, 2, 6, 7, 8, 10], "post_fil": [0, 1, 2], "post_input": [0, 1, 2], "post_result": [0, 1, 2], "post_start": [0, 1, 2], "post_termin": [0, 1, 2], "pred": [1, 2], "predict": [0, 1, 2, 9, 16], "predict_async": [0, 1, 2, 4], "predict_multi_gpu": [0, 1, 2], "predict_result": 9, "preprocess": [0, 1, 2, 12, 13, 16], "preprocess_fil": 2, "print": [0, 1, 4, 16, 18], "print_subprocess_out_err": [0, 1, 4], "prob": [0, 6, 7], "probabl": [0, 12], "proc": 4, "process": [0, 1, 5, 12, 14], "process_answ": [0, 12, 14], "process_lin": [0, 12, 14], "process_messag": [0, 1, 5], "process_punctu": [0, 12, 14], "processor": 2, "progressfil": [0, 8, 11], "project": 0, "prompt": [0, 1, 5, 12, 13, 16], "prompt_typ": 5, "punctuat": [0, 12, 14], "py": [2, 4], "queri": 16, "read": [0, 1, 2, 8, 11], "refresh": [8, 9], "refresh_author": [8, 9], "remov": [0, 1, 2], "remove_stop_str": [0, 1, 2], "request": [0, 2, 6, 7], "respons": [8, 9], "restructuredtext": 0, "result": [0, 1, 2, 8, 9, 11, 14], "results_new": [1, 2], "retri": [7, 9], "retry_interv": 7, "return": 16, "run": [0, 1, 4, 6], "run_command": [0, 6, 7], "run_judge_infer": [0, 6, 7], "run_loss_ev": [0, 6, 7], "run_mt_bench_ev": [0, 6, 7], "run_next_word_prob_ev": [0, 6, 7], "run_post_ev": [0, 6, 7], "run_predict_multi_gpu": [0, 1, 4], "run_task_infer": [0, 6, 7], "run_text_ev": [0, 6, 7], "runtimeerror": 7, "sampl": [0, 1, 2, 5], "save": [7, 8, 9, 13, 16], "save_dir": [7, 13, 16], "save_fil": [8, 9], "score": [16, 18], "secret": 9, "see": 0, "semaphor": [2, 9], "send": [0, 6, 7], "send_request": [0, 6, 7], "server": [0, 1, 4], "session": 9, "set": [0, 1, 2, 8, 10], "set_head": [8, 10], "set_result": [0, 1, 2], "size": 11, "sonnet": 9, "src": 10, "start": [1, 2, 6, 7], "static": 9, "step1": [13, 16], "stop": [0, 1, 2], "str": [0, 1, 2, 7, 9, 10, 16, 18], "string": 13, "sub": 7, "submit": [0, 8, 11], "submit_result": [8, 11], "submodul": 7, "subprocess": [0, 1, 4], "syntax": 0, "target": 9, "target_key": 9, "task": [0, 2, 6, 7, 11], "temperatur": 9, "termin": [0, 1, 2, 4, 6, 7], "terminate_inference_engin": [0, 6, 7], "terminate_subprocess": [0, 1, 4], "text": [0, 1, 2, 6, 7, 9, 14], "text2text": [8, 9], "texts2text": [7, 8, 9], "textvqa": [0, 12], "the": [0, 13], "timeout": [9, 10], "tmpl": 16, "to": [0, 1, 2, 5, 13], "token": [0, 1, 2, 5], "tokenizer_path": 2, "tool": 0, "tqdm": 9, "tri": 9, "true": [2, 4, 5, 16], "try_num": 9, "tupl": 2, "type": [1, 2, 5, 14], "type_": 14, "uid": [1, 2], "union": [2, 10], "upload": [0, 12, 16], "upload_pass_format": [0, 12, 16], "url": [7, 9, 10], "us": 9, "use": 0, "util": 0, "v1": 9, "v2": 9, "v3": 9, "val": [0, 12], "valu": 10, "vllm": 4, "vtuber": 9, "wait": [0, 6, 7], "wait_for_external_api": [0, 6, 7], "wait_for_infer": [0, 6, 7], "word": [0, 6, 7, 12], "worker": 2, "write": [0, 1, 2], "write_result": [0, 1, 2], "write_result_async": [0, 1, 2], "written": 2, "your": 0, "\u4e00\u4e2a": [7, 9, 10, 14], "\u4e00\u5757": 4, "\u4e00\u81f4": 9, "\u4e09\u6b21": 14, "\u4e0b\u6e38": 2, "\u4e24\u4e2a": 14, "\u4e4b\u95f4": 4, "\u4ea7\u751f": 7, "\u4ec5\u5f53": 2, "\u4ee3\u7801": [2, 4, 5, 7, 9, 10, 11, 13, 14, 16, 17, 18], "\u4ee5\u4e0a": 14, "\u4ee5\u4e0b": 7, "\u4ee5\u53ca": 4, "\u4efb\u4f55": 7, "\u4efb\u52a1": [2, 4, 7, 18], "\u4efb\u610f": 4, "\u4f20\u5165": [2, 9], "\u4f20\u8f93": 10, "\u4f20\u9012": 18, "\u4f5c\u4e3a": 7, "\u4f7f\u7528": [0, 4, 7, 9], "\u4f7f\u7528\u7387": 4, "\u4f9b\u4e3b": 2, "\u4fdd\u5b58": [7, 16], "\u4fe1\u53f7": 7, "\u4fe1\u606f": [2, 7, 9], "\u505c\u6b62": 2, "\u5141\u8bb8": 7, "\u5143\u7d20": 9, "\u5168\u5c40": 2, "\u5168\u90e8": [2, 7], "\u5173\u95ed": 9, "\u5176\u4ed6": 18, "\u518d\u542f\u52a8": 7, "\u5199\u5165": [2, 4], "\u51c6\u5907": 7, "\u51c6\u786e": 16, "\u51c6\u786e\u7387": 16, "\u51fd\u6570": [7, 16, 18], "\u5206\u6570": [14, 18], "\u5206\u9694": 2, "\u5217\u8868": [7, 9], "\u521b\u5efa": 2, "\u521d\u59cb": [9, 10], "\u521d\u59cb\u5316": [9, 10], "\u5224\u65ad": [2, 5], "\u5237\u65b0": 9, "\u529f\u80fd": 16, "\u52a0\u8f7d": 2, "\u5305\u542b": [2, 7, 9, 16, 18], "\u5305\u62ec": [2, 7], "\u5339\u914d": [14, 16], "\u539f\u59cb": 16, "\u539f\u59cb\u6570\u636e": 16, "\u53bb\u9664": 2, "\u53c2\u6570": [2, 7, 9, 10, 16, 18], "\u53d1\u9001": [7, 10], "\u53ef\u4ee5": [7, 9], "\u53ef\u7528": 16, "\u53ef\u80fd": 7, "\u540c\u540d": 2, "\u540c\u82b1": 0, "\u540c\u82b1\u987a": 0, "\u540d\u79f0": [7, 9, 16], "\u5426\u5219": [7, 9], "\u542f\u52a8": [2, 4, 7], "\u54cd\u5e94": 10, "\u56fe\u50cf": 7, "\u56fe\u50cf\u5904\u7406": 7, "\u56fe\u6587": 9, "\u56fe\u7247": 9, "\u5730\u5740": 7, "\u5747\u8861": 4, "\u57fa\u4e8e": 4, "\u57fa\u7840": 10, "\u5904\u7406": [5, 7, 16], "\u5907\u6ce8": 7, "\u5916\u90e8": 7, "\u591a\u4e2a": [2, 4, 9], "\u591a\u5361": 4, "\u5934\u90e8": 10, "\u5982\u679c": [2, 5, 7, 9], "\u5b57\u5178": [7, 9], "\u5b57\u6bb5": 10, "\u5b57\u6bb5\u540d": 10, "\u5b57\u7b26": [7, 16], "\u5b57\u7b26\u4e32": [7, 16], "\u5b58\u50a8": 7, "\u5b8c\u6210": [2, 7], "\u5b8c\u6574": 5, "\u5b9a\u4e49": 7, "\u5b9a\u4f4d": 7, "\u5b9e\u73b0": [4, 7], "\u5bc6\u94a5": 9, "\u5bf9\u8bdd": 9, "\u5bf9\u8c61": [7, 9], "\u5bfb\u627e": 9, "\u5c01\u88c5": 10, "\u5d4c\u5957": 9, "\u5e94\u4e3a": [7, 18], "\u5e94\u7528": 9, "\u5f02\u5e38": 7, "\u5f02\u6b65": [2, 4, 7], "\u5f15\u53d1": 7, "\u5f15\u64ce": 7, "\u5f52\u4e00\u5316": 18, "\u5fc5\u987b": 7, "\u610f\u5916": 7, "\u6216\u8005": [2, 9], "\u6240\u5728": [9, 16], "\u6240\u6709": [2, 7], "\u6267\u884c": 7, "\u6269\u5c55": 16, "\u6279\u91cf": 9, "\u627e\u5230": 9, "\u62fc\u63a5": 5, "\u6301\u7eed": 7, "\u6307\u5b9a": [2, 7], "\u6307\u5bfc": 16, "\u63a5\u53e3": [7, 9], "\u63a8\u7406": [2, 4, 7], "\u63a8\u7406\u65b9\u6cd5": 7, "\u63d0\u4ea4": [2, 7], "\u63d0\u793a": 16, "\u641c\u7d22": 0, "\u64cd\u4f5c": 7, "\u652f\u6301": [2, 9], "\u6570\u636e": [2, 4, 5, 7, 9, 10, 16, 18], "\u6570\u636e\u6587\u4ef6": [2, 7], "\u6570\u636e\u7c7b\u578b": 7, "\u6570\u91cf": [2, 16], "\u6587\u4ef6": [2, 7, 10, 16, 18], "\u6587\u4ef6\u540d": 7, "\u6587\u672c": [2, 4, 7, 9], "\u6587\u672c\u5904\u7406": 7, "\u65b9\u6cd5": 7, "\u65f6\u4f1a": 7, "\u65f6\u95f4": [7, 9, 10], "\u662f\u5426": [2, 5, 7], "\u66f4\u65b0": 7, "\u6700\u5927": 9, "\u6700\u7ec8": 18, "\u672a\u6307\u5b9a": 2, "\u672c\u5730": 7, "\u672c\u5904": 7, "\u672c\u6570": [2, 16], "\u6784\u5efa": 16, "\u679a\u4e3e": 7, "\u6807\u51c6": [14, 16, 18], "\u6807\u51c6\u5316": 14, "\u6807\u51c6\u7b54\u6848": [16, 18], "\u6837\u672c": [2, 16], "\u6837\u672c\u6570": [2, 16], "\u6839\u636e": [2, 7], "\u683c\u5f0f": [2, 5, 7, 9, 14, 16, 18], "\u683c\u5f0f\u5316": 16, "\u6846\u67b6": 0, "\u68c0\u67e5": 7, "\u6a21\u5757": 0, "\u6a21\u578b": [0, 7, 9, 16, 18], "\u6a21\u5f0f": 9, "\u6a21\u6001": [0, 9], "\u6a21\u677f": 16, "\u6b21\u6570": 9, "\u6b63\u786e": [7, 16], "\u6b64\u534f\u7a0b": 7, "\u6b65\u9aa4": 7, "\u6bb5\u503c": 10, "\u6bcf\u884c": 18, "\u6ca1\u6709": 7, "\u6ce8\u610f": [7, 9], "\u6d41\u7a0b": 7, "\u6d4b\u8bd5": 7, "\u6d88\u606f": 7, "\u6dfb\u52a0": 2, "\u6e29\u5ea6": 9, "\u6e90\u4ee3\u7801": [2, 4, 5, 7, 9, 10, 11, 13, 14, 16, 17, 18], "\u6e90\u6587\u4ef6": 2, "\u7279\u5b9a": 7, "\u72b6\u6001": [2, 7], "\u751f\u6210": [4, 7, 9], "\u751f\u6548": 2, "\u7528\u4e8e": [4, 7, 16, 18], "\u7528\u7387": 4, "\u7684\u8bdd": 5, "\u76d1\u63a7": 7, "\u76ee\u5f55": [2, 7, 16], "\u76ee\u6807": 9, "\u76f4\u63a5": 7, "\u76f8\u5173": [2, 7], "\u76f8\u5e94": 7, "\u786e\u5b9a": 7, "\u793a\u4f8b": [0, 7, 18], "\u7acb\u5373": 7, "\u7aef\u70b9": 10, "\u7b49\u5f85": 7, "\u7b54\u6848": [14, 16, 18], "\u7b80\u5355": 0, "\u7ba1\u7406": 7, "\u7c7b\u578b": [2, 7, 9, 10, 16, 18], "\u7d22\u5f15": 0, "\u7ebf\u7a0b": 2, "\u7ec8\u6b62": 7, "\u7ed3\u675f": 2, "\u7ed3\u679c": [2, 7, 9, 16, 18], "\u7edf\u4e00": 4, "\u81ea\u52a8": [2, 7], "\u82f1\u6587": 2, "\u83b7\u53d6": 2, "\u884c\u4e3a": 7, "\u8868\u73b0": 18, "\u88c1\u5224": [7, 16], "\u88c1\u5224\u5458": 7, "\u89e3\u6790": 7, "\u8ba1\u7b97": [14, 16], "\u8ba4\u8bc1": 9, "\u8bbe\u7f6e": [7, 10], "\u8bc4\u4f30": [0, 7, 16, 18], "\u8bf7\u6c42": [7, 9, 10], "\u8bfb\u53d6": [2, 4], "\u8c03\u7528": [2, 7, 9], "\u8d1f\u8d23": 7, "\u8d1f\u8f7d": 4, "\u8d44\u6e90": 7, "\u8d85\u65f6": [9, 10], "\u8def\u5f84": [2, 7, 9, 16, 18], "\u8eab\u4efd": 9, "\u8eab\u4efd\u9a8c\u8bc1": 9, "\u8f6c\u6362": [2, 7, 16], "\u8f93\u5165": [2, 5, 7, 16, 18], "\u8f93\u5165\u8f93\u51fa": 2, "\u8f93\u51fa": [2, 7, 16], "\u8fc7\u7a0b": 7, "\u8fd0\u884c": 7, "\u8fd4\u56de": [2, 4, 5, 7, 9, 10, 16, 18], "\u8fd4\u56de\u503c": 7, "\u8fdb\u5ea6": [7, 9], "\u8fdb\u5ea6\u6761": 9, "\u8fdb\u7a0b": [2, 4, 7], "\u8fdb\u884c": 5, "\u9000\u51fa": [2, 7], "\u9002\u5f53": 7, "\u9009\u62e9": [7, 16], "\u9009\u62e9\u9898": 16, "\u9009\u9879": 16, "\u9017\u53f7": 2, "\u901a\u7528": 9, "\u901a\u8fc7": [4, 7], "\u914d\u7f6e": [7, 18], "\u91ca\u653e": 7, "\u9519\u8bef": 9, "\u95ee\u9898": 16, "\u961f\u5217": 2, "\u9664\u4ee5": 16, "\u9700\u8981": 7, "\u9875\u9762": 0, "\u987a\u5e8f": 9, "\u9884\u5904\u7406": [7, 16], "\u9884\u6d4b": [2, 16, 18], "\u9a8c\u8bc1": 9, "\u9ed8\u8ba4": [9, 16]}, "titles": ["llm-eval documentation", "inference", "inference.data_server", "inference.predict_async", "inference.predict_multi_gpu", "inference.preprocess", "main", "run", "tools", "tools.ExternalApi", "tools.HttpRequest", "tools.PaasSubmitter", "utils", "utils.eval_MathVista_MINI", "utils.eval_TextVQA_VAL", "utils.eval_asr", "utils.eval_mmmu", "utils.eval_next_word_probability", "utils.eval_ocr_bench"], "titleterms": {"and": 0, "asr": 15, "async": 3, "bench": 18, "content": [0, 1, 6, 8, 12], "data": 2, "data_serv": 2, "document": 0, "eval": [0, 13, 14, 15, 16, 17, 18], "eval_asr": 15, "eval_mathvista_mini": 13, "eval_mmmu": 16, "eval_next_word_prob": 17, "eval_ocr_bench": 18, "eval_textvqa_v": 14, "externalapi": 9, "gpu": 4, "httprequest": 10, "indic": 0, "infer": [1, 2, 3, 4, 5], "instal": 0, "llm": 0, "main": 6, "mathvista": 13, "mini": 13, "mmmu": 16, "modul": 0, "multi": 4, "next": 17, "ocr": 18, "paassubmitt": 11, "predict": [3, 4], "predict_async": 3, "predict_multi_gpu": 4, "preprocess": 5, "probabl": 17, "quick": 0, "run": 7, "server": 2, "start": 0, "tabl": 0, "textvqa": 14, "tool": [8, 9, 10, 11], "util": [12, 13, 14, 15, 16, 17, 18], "val": 14, "word": 17}})