import math
import librosa
import base64
from io import BytesIO
from PIL import Image


IMAGE_FACTOR = 28
# MIN_PIXELS = 4 * 28 * 28
MIN_PIXELS = 10 * 10 * 28 * 28  # for OCRBench
MAX_PIXELS = 16384 * 28 * 28
MAX_RATIO = 200

VIDEO_MIN_PIXELS = 128 * 28 * 28
VIDEO_MAX_PIXELS = 768 * 28 * 28
FRAME_FACTOR = 2
FPS = 2.0
FPS_MIN_FRAMES = 4
FPS_MAX_FRAMES = 768


def load_multimodal_data(
    processor,
    image: list[str] | None = None,
    audio: list[str] | None = None,
    return_dict=False,
):
    def open_image(x):
        if x.startswith("data:image"):
            x = x.split(',', 1)[1]
            image_data = base64.b64decode(x)
            return Image.open(BytesIO(image_data))
        else:
            return Image.open(x)

    if image is not None:
        image = [open_image(x) for x in image]
        image = [to_rgb(x) for x in image]
        # For Qwen2-VL, Qwen2.5-VL, Omni, 解决processor短边小于28的bug
        # OCRBench数据集需要调整，MIN_PIXELS
        # TODO:需要根据模型和数据集类型调整
        image = [resize_image(x, min_pixels=MIN_PIXELS) for x in image]

    if audio is not None:
        audio = [
            librosa.load(x, sr=processor.feature_extractor.sampling_rate)[0]
            for x in audio
        ]

    if return_dict:
        return {k: v for k, v in [('image', image), ('audio', audio)] if v is not None}
    else:
        return image, audio


def to_rgb(pil_image: Image.Image) -> Image.Image:
      if pil_image.mode == 'RGBA':
          white_background = Image.new("RGB", pil_image.size, (255, 255, 255))
          white_background.paste(pil_image, mask=pil_image.split()[3])  # Use alpha channel as mask
          return white_background
      else:
          return pil_image.convert("RGB")


def round_by_factor(number: int, factor: int) -> int:
    """Returns the closest integer to 'number' that is divisible by 'factor'."""
    return round(number / factor) * factor


def ceil_by_factor(number: int, factor: int) -> int:
    """Returns the smallest integer greater than or equal to 'number' that is divisible by 'factor'."""
    return math.ceil(number / factor) * factor


def floor_by_factor(number: int, factor: int) -> int:
    """Returns the largest integer less than or equal to 'number' that is divisible by 'factor'."""
    return math.floor(number / factor) * factor


def smart_resize(
    height: int, width: int, factor: int = IMAGE_FACTOR, min_pixels: int = MIN_PIXELS, max_pixels: int = MAX_PIXELS
) -> tuple[int, int]:
    """
    Rescales the image so that the following conditions are met:

    1. Both dimensions (height and width) are divisible by 'factor'.

    2. The total number of pixels is within the range ['min_pixels', 'max_pixels'].

    3. The aspect ratio of the image is maintained as closely as possible.
    """
    if max(height, width) / min(height, width) > MAX_RATIO:
        raise ValueError(
            f"absolute aspect ratio must be smaller than {MAX_RATIO}, got {max(height, width) / min(height, width)}"
        )
    h_bar = max(factor, round_by_factor(height, factor))
    w_bar = max(factor, round_by_factor(width, factor))
    if h_bar * w_bar > max_pixels:
        beta = math.sqrt((height * width) / max_pixels)
        h_bar = floor_by_factor(height / beta, factor)
        w_bar = floor_by_factor(width / beta, factor)
    elif h_bar * w_bar < min_pixels:
        beta = math.sqrt(min_pixels / (height * width))
        h_bar = ceil_by_factor(height * beta, factor)
        w_bar = ceil_by_factor(width * beta, factor)
    return h_bar, w_bar


def resize_image(image, min_pixels):
    width, height = image.size
    min_pixels = MIN_PIXELS
    max_pixels = MAX_PIXELS
    resized_height, resized_width = smart_resize(
        height,
        width,
        factor=IMAGE_FACTOR,
        min_pixels=min_pixels,
        max_pixels=max_pixels,
    )
    image = image.resize((resized_width, resized_height))

    return image
